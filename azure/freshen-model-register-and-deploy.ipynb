{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/deployment/deploy-to-cloud/model-register-and-deploy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register model and deploy as webservice in ACI\n",
    "\n",
    "Following this notebook, you will:\n",
    "\n",
    " - Learn how to register a model in your Azure Machine Learning Workspace.\n",
    " - Deploy your model as a web service in an Azure Container Instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the [configuration notebook](../../../configuration.ipynb) to install the Azure Machine Learning Python SDK and create a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.17.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "\n",
    "# Check core SDK version number.\n",
    "print('SDK version:', azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "\n",
    "Create a [Workspace](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace%28class%29?view=azure-ml-py) object from your persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "create workspace"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nabila-ml\n",
      "nabila-amplify-rg\n",
      "eastus\n",
      "38d95926-fedd-400d-a5d4-60c70a647707\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create trained model\n",
    "\n",
    "For this example, we will train a small model on scikit-learn's [diabetes dataset](https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import sklearn\n",
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#alexnet = models.alexnet(pretrained=True)\n",
    "#joblib.dump(alexnet, 'alexnet_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model\n",
    "\n",
    "Register a file or folder as a model by calling [Model.register()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none-).\n",
    "\n",
    "In addition to the content of the model file itself, your registered model will also store model metadata -- model description, tags, and framework information -- that will be useful when managing and deploying models in your workspace. Using tags, for instance, you can categorize your models and apply filters when listing models in your workspace. Also, marking this model with the scikit-learn framework will simplify deploying it as a web service, as we'll see later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.register(workspace=ws,\n",
    "                       model_name='alexnet',                # Name of the registered model in your workspace.\n",
    "                       model_path='alexnet_model.pkl',  # Local file to upload and register as a model.\n",
    "\n",
    "                       resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=1),\n",
    "                       description='Predict image label',\n",
    "                       tags={'area': 'image', 'type': 'recognition'}\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(name='alexnet', workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "register model from file",
     "sample-model-register"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet\talexnet:4\t4\n"
     ]
    }
   ],
   "source": [
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model\n",
    "\n",
    "Deploy your model as a web service using [Model.deploy()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py#deploy-workspace--name--models--inference-config--deployment-config-none--deployment-target-none-). Web services take one or more models, load them in an environment, and run them on one of several supported deployment targets. For more information on all your options when deploying models, see the [next steps](#Next-steps) section at the end of this notebook.\n",
    "\n",
    "For this example, we will deploy your scikit-learn model to an Azure Container Instance (ACI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a custom environment\n",
    "\n",
    "If you want more control over how your model is run, if it uses another framework, or if it has special runtime requirements, you can instead specify your own environment and scoring method. Custom environments can be used for any model you want to deploy.\n",
    "\n",
    "Specify the model's runtime environment by creating an [Environment](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.environment%28class%29?view=azure-ml-py) object and providing the [CondaDependencies](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.conda_dependencies.condadependencies?view=azure-ml-py) needed by your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "\n",
    "environment = Environment('my-freshen-environment')\n",
    "environment.python.conda_dependencies = CondaDependencies.create(pip_packages=[\n",
    "    'azureml-defaults',\n",
    "    'inference-schema[numpy-support]',\n",
    "    'joblib',\n",
    "    'numpy',\n",
    "    'torch',\n",
    "    'torchvision',\n",
    "    'scikit-learn=={}'.format(sklearn.__version__)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from azureml.core.model import Model\n",
    "from torchvision import transforms\n",
    "from PIL import Image \n",
    "\n",
    "transform = transforms.Compose([            \n",
    " transforms.Resize(256),                    \n",
    " transforms.CenterCrop(224),                \n",
    " transforms.ToTensor(),                     \n",
    " transforms.Normalize(                  \n",
    " mean=[0.485, 0.456, 0.406],                \n",
    " std=[0.229, 0.224, 0.225]                  \n",
    " )])\n",
    "\n",
    "\n",
    "def preprocess_data(img):\n",
    "    print(f' Image shape in preprocess data: {img.shape}')\n",
    "    img = Image.fromarray(img, 'RGB')\n",
    "    print(f' Image type: {type(img)}')\n",
    "    img_t = transform(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "    return batch_t\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # retrieve the path to the model file using the model name\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'alexnet_model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "\n",
    "    try:\n",
    "        print('in the try, received data')\n",
    "        data = np.array(json.loads(raw_data)['data'])\n",
    "        print('after the read')\n",
    "        # make prediction\n",
    "        print(f'Length of the data list: {len(list(data))}')\n",
    "        img = preprocess_data(data)\n",
    "        print('after the preprocess')\n",
    "        y = model(img)\n",
    "        print('after inference')\n",
    "        #prob = F.softmax(y, dim=1)[0]\n",
    "        #_, ind = torch.topk(y, 1) \n",
    "        return y.tolist()[0]\n",
    "    \n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using a custom environment, you must also provide Python code for initializing and running your model. An example script is included with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "from torchvision import transforms\n",
    "from PIL import Image \n",
    "\n",
    "transform = transforms.Compose([            \n",
    " transforms.Resize(256),                    \n",
    " transforms.CenterCrop(224),                \n",
    " transforms.ToTensor(),                     \n",
    " transforms.Normalize(                  \n",
    " mean=[0.485, 0.456, 0.406],                \n",
    " std=[0.229, 0.224, 0.225]                  \n",
    " )])\n",
    "\n",
    "\n",
    "def preprocess_data(img):\n",
    "    print(f' Image shape in preprocess data: {img.shape}')\n",
    "    img = Image.fromarray(img, 'RGB')\n",
    "    print(f' Image type: {type(img)}')\n",
    "    img_t = transform(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "    return batch_t\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # retrieve the path to the model file using the model name\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'alexnet_model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(raw_data):\n",
    "\n",
    "    try:\n",
    "        print('in the try, received data')\n",
    "        model = joblib.load('alexnet_model.pkl')\n",
    "        data = np.array(json.loads(raw_data)['data'])\n",
    "        print('after the read')\n",
    "        # make prediction\n",
    "        print(f'Length of the data list: {len(list(data))}')\n",
    "        img = preprocess_data(data)\n",
    "        print('after the preprocess')\n",
    "        y = model(img)\n",
    "        print('after inference')\n",
    "        prob = F.softmax(y, dim=1)[0]\n",
    "        return y.tolist()[0]\n",
    "    \n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "\n",
    "img = cv2.imread('banana.jpg')\n",
    "input_data = {'data': img.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('image.txt', 'w') as file:\n",
    " #    file.write(json.dumps(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the try, received data\n",
      "after the read\n",
      "Length of the data list: 667\n",
      " Image shape in preprocess data: (667, 1000, 3)\n",
      " Image type: <class 'PIL.Image.Image'>\n",
      "after the preprocess\n",
      "after inference\n"
     ]
    }
   ],
   "source": [
    "y = run(json.dumps(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-a2d3d6726c7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "import pickle\n",
      "import json\n",
      "import joblib\n",
      "import numpy as np\n",
      "import torch\n",
      "from azureml.core.model import Model\n",
      "from torchvision import transforms\n",
      "from PIL import Image \n",
      "\n",
      "transform = transforms.Compose([            \n",
      " transforms.Resize(256),                    \n",
      " transforms.CenterCrop(224),                \n",
      " transforms.ToTensor(),                     \n",
      " transforms.Normalize(                  \n",
      " mean=[0.485, 0.456, 0.406],                \n",
      " std=[0.229, 0.224, 0.225]                  \n",
      " )])\n",
      "\n",
      "\n",
      "def preprocess_data(img):\n",
      "    print(f' Image shape in preprocess data: {img.shape}')\n",
      "    img = Image.fromarray(img, 'RGB')\n",
      "    print(f' Image type: {type(img)}')\n",
      "    img_t = transform(img)\n",
      "    batch_t = torch.unsqueeze(img_t, 0)\n",
      "    return batch_t\n",
      "\n",
      "def init():\n",
      "    global model\n",
      "    # retrieve the path to the model file using the model name\n",
      "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'alexnet_model.pkl')\n",
      "    model = joblib.load(model_path)\n",
      "\n",
      "def run(raw_data):\n",
      "\n",
      "    try:\n",
      "        print('in the try, received data')\n",
      "        data = np.array(json.loads(raw_data)['data'])\n",
      "        print('after the read')\n",
      "        # make prediction\n",
      "        print(f'Length of the data list: {len(list(data))}')\n",
      "        img = preprocess_data(data)\n",
      "        print('after the preprocess')\n",
      "        y = model(img)\n",
      "        print('after inference')\n",
      "        #prob = F.softmax(y, dim=1)[0]\n",
      "        #_, ind = torch.topk(y, 1) \n",
      "        return y.tolist()[0]\n",
      "    \n",
      "    except Exception as e:\n",
      "        error = str(e)\n",
      "        return error\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('score.py') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy your model in the custom environment by providing an [InferenceConfig](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.inferenceconfig?view=azure-ml-py) object to [Model.deploy()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py#deploy-workspace--name--models--inference-config--deployment-config-none--deployment-target-none-). In this case we are also using the [AciWebservice.deploy_configuration()](https://docs.microsoft.com/python/api/azureml-core/azureml.core.webservice.aci.aciwebservice#deploy-configuration-cpu-cores-none--memory-gb-none--tags-none--properties-none--description-none--location-none--auth-enabled-none--ssl-enabled-none--enable-app-insights-none--ssl-cert-pem-file-none--ssl-key-pem-file-none--ssl-cname-none--dns-name-label-none--) method to generate a custom deploy configuration.\n",
    "\n",
    "**Note**: This step can take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": [
     "azuremlexception-remarks-sample",
     "sample-aciwebservice-deploy-config"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running.........................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "\n",
    "service_name = 'freshen-service'\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=environment)\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name=service_name,\n",
    "                       models=[model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=aci_config,\n",
    "                       overwrite=True)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After your model is deployed, make a call to the web service using [service.run()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice%28class%29?view=azure-ml-py#run-input-)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = service.scoring_uri\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "response = requests.post(url, data=json.dumps(input_data), headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.array(response.json())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished testing your service, clean up the deployment with [service.delete()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice%28class%29?view=azure-ml-py#delete--)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    " - To run a production-ready web service, see the [notebook on deployment to Azure Kubernetes Service](../production-deploy-to-aks/production-deploy-to-aks.ipynb).\n",
    " - To run a local web service, see the [notebook on deployment to a local Docker container](../deploy-to-local/register-model-deploy-local.ipynb).\n",
    " - For more information on datasets, see the [notebook on training with datasets](../../work-with-data/datasets-tutorial/train-with-datasets/train-with-datasets.ipynb).\n",
    " - For more information on environments, see the [notebook on using environments](../../training/using-environments/using-environments.ipynb).\n",
    " - For information on all the available deployment targets, see [&ldquo;How and where to deploy models&rdquo;](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-and-where#choose-a-compute-target)."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "vaidyas"
   }
  ],
  "category": "deployment",
  "compute": [
   "None"
  ],
  "datasets": [
   "Diabetes"
  ],
  "deployment": [
   "Azure Container Instance"
  ],
  "exclude_from_index": false,
  "framework": [
   "Scikit-learn"
  ],
  "friendly_name": "Register model and deploy as webservice",
  "index_order": 3,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "star_tag": [
   "featured"
  ],
  "tags": [
   "None"
  ],
  "task": "Deploy a model with Azure Machine Learning"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
